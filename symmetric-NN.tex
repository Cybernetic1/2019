\input{../YKY-preamble.tex}

\title{Symmetric neural networks}
\author{YKY}

\begin{document}
\maketitle

\section{General case for $y = A x$}

\begin{equation}
\boxed{\mbox{original}} \quad y_j = \sum_i a_{ij} x_i .
\end{equation}

Equivariance implies:
\begin{eqnarray}
\boxed{\mbox{swapped}} \quad y_j ( \sigma(x_j \; x_k) x) &=& \sigma \cdot y_j = y_k \quad \boxed{\mbox{original}} \\
\sum_{i \neq j,k} a_{ij} x_i + a_{kj} x_j + a_{jj} x_k &=& \sum_{i \neq j,k} a_{ik} x_i + a_{jk} x_j + a_{kk} x_k . \nonumber
\end{eqnarray}

% for $(j \; k) \in \mathfrak{S}_n$.

Comparing coefficients yields:
\begin{eqnarray}
a_{ij} &=& a_{ik} \quad \quad \forall \; j, k, (i \neq j, k) \nonumber \\
a_{kj} &=& a_{jk} \quad \quad \forall \; j, k \nonumber \\
a_{jj} &=& a_{kk} \quad \quad \forall \; j, k .
\end{eqnarray}

In other words, the matrix $A$ is of the form:
\begin{equation}
A = \alpha I + \beta 1 1^T .
\end{equation}

\section{Case for $y_k = A_k x \cdot x$}

The general form of a ``quadratic'' vector function is:
\begin{equation}
y = (A x) \cdot x + B x + C .
\end{equation}

We just focus on the quadratic term $(A x) \cdot x$:
\begin{equation}
\boxed{\mbox{original}} \quad y_k = \sum_j \left[ \sum_i a_{ij}^k x_i \right] x_j .
\end{equation}
Note that the matrix $A$ is ``3D'' and has $N \times N \times N$ entries.

Equivariance implies:
\begin{equation}
\boxed{\mbox{swapped}} \quad y_k ( \sigma(x_k \; x_h) \cdot x) = \sigma \cdot y_k = y_h \quad \boxed{\mbox{original}}
% \sum_{j \neq h,k} \sum_{i \neq h,k} a_{ij}^k x_i x_j + a_{hh}^k x_k^2 + a_{kh}^k x_h x_k + a_{hk}^k x_k x_h + a_{kk}^k x_h^2 &=& \sum_{j \neq h,k} \sum_{i \neq h,k} a_{ij}^h x_i x_j + a_{hh}^h x_h^2 + a_{kh}^h x_k x_h + a_{hk}^h x_h x_k + a_{kk}^h x_k^2 \nonumber
\end{equation}

\begin{eqnarray}
LHS &=& \sum_j \left[ \sum_{i \neq h,k} a^k_{ij} x_i + a^k_{hj} x_k + a^k_{kj} x_h \right] \sigma \cdot x_j \nonumber \\
&=& \sum_{j \neq h,k} \left[ \sum_{i \neq h,k} a^k_{ij} x_i + a^k_{hj} x_k + a^k_{kj} x_h \right] x_j
+ \left[ \sum_{i \neq h,k} a^k_{ih} x_i + a^k_{hh} x_k + a^k_{kh} x_h \right] x_k
+ \left[ \sum_{i \neq h,k} a^k_{ik} x_i + a^k_{hk} x_k + a^k_{kk} x_h \right] x_h \nonumber \\
&=& \sum_{j \neq h,k} \sum_{i \neq h,k} a^k_{ij} x_i x_j + \sum_{j \neq h,k} a^k_{hj} x_k x_j + \sum_{j \neq h,k} a^k_{kj} x_h x_j \nonumber \\
&& + \sum_{i \neq h,k} a^k_{ih} x_i x_k + a^k_{hh} x^2_k + a^k_{kh} x_h x_k \nonumber \\
&& + \sum_{i \neq h,k} a^k_{ik} x_i x_h + a^k_{hk} x_k x_h + a^k_{kk} x^2_h \nonumber \\
RHS &=& \sum_j \left[ \sum_i a_{ij}^h x_i \right] x_j \nonumber \\
&=& \sum_{j \neq h,k} \sum_{i \neq h,k} a^h_{ij} x_i x_j + \sum_{j \neq h,k} a^h_{kj} x_k x_j + \sum_{j \neq h,k} a^h_{hj} x_h x_j \nonumber \\
&& + \sum_{i \neq h,k} a^h_{ik} x_i x_k + a^h_{kk} x^2_k + a^h_{hk} x_h x_k \nonumber \\
&& + \sum_{i \neq h,k} a^h_{ih} x_i x_h + a^h_{kh} x_k x_h + a^h_{hh} x^2_h
\end{eqnarray}

Comparing coefficients yields:
\begin{alignat}{3}
a_{ij}^h &= a_{ij}^k && \forall \; h,k, (i \neq h,k, j \neq h,k) \nonumber \\
a_{kj}^h &= a_{hj}^k && \forall \; h,k, (j \neq h,k) \nonumber \\
a_{hj}^h &= a_{kj}^k && \forall \; h,k, (j \neq h,k) \nonumber \\
a_{ik}^h &= a_{ih}^k && \forall \; h,k, (i \neq h,k) \nonumber \\
a_{ih}^h &= a_{ik}^k && \forall \; h,k, (i \neq h,k) \nonumber \\
a_{kk}^h &= a_{hh}^k && \forall \; h,k \nonumber \\
a_{hh}^h &= a_{kk}^k && \forall \; h,k \nonumber \\
a_{hk}^h + a_{kh}^h &= a_{hk}^k + a_{kh}^k \quad && \forall \; h,k .
\end{alignat}

How many different colors?
\begin{equation}
\begin{tabular}{c c c c}
$N = 2$ .... & 6 & / 8 & = 75\% \\
$N = 3$ .... & 9 & / 27 & = 33.3\% \\
$N = 4$ .... & 11 & / 64 & = 17/2\% \\
$N = 5$ .... & 13 & / 125 & = 10.4\% \\
$N = 6$ .... & 15 & / 216 & = 6.9\%
\end{tabular}
\end{equation}

There would be $N$ \textbf{blocks} of $N \times N$ matrices.

All diagonals consists of 2 colors, regardless of $N$ (from 2nd and 3rd equations).  This leaves $N (N - 1)$ non-diagonal entries per block.

Non-diagonal entries of different blocks are equal, if the block indices are different from the row and column indices.  Out of $N$ blocks there would be 2 different sets of non-diagonal weights.  (This comes from the 1st equation.)

The last equation causes non-diagonal weights to have a certain symmetry about the diagonal.  

\section{With output space ``folded in half''}

Now suppose the output is only $1/2$ the dimension of the input.  Define a new form of equivariance such that the input permutation would act on the output as ``folded in half''. 

In other words, equivariance is changed to:
\begin{equation}
\boxed{\mbox{swapped}} \quad y_k \cdot \sigma(x_k \; x_h) = y_h \mbox{  or  } y_{h-N/2} \quad \boxed{\mbox{original}} \end{equation}
where $\tau$ is $\sigma$ acting on $y$ as double its length and identifying $y_i = y_{i + N/2}$.

\subsection{Linear case}

Just notice that the dimension of $y$ is halved:
\begin{equation}
\boxed{\mbox{original}} \quad y_j = \sum_i a_{ij} x_i .
\end{equation}

``Folded'' equivariance implies:
\begin{eqnarray}
\boxed{\mbox{swapped}} \quad y_j ( \sigma(x_j \; x_k) x) %\mbox{ or } y_m ( \sigma(x_m \; x_k) x)
&=& \sigma \cdot y_j = y_k \quad \boxed{\mbox{original}} \\
\sum_{i \neq j,k} a_{ij} x_i + a_{kj} x_j + a_{jj} x_k &=& \sum_{i \neq j,k} a_{ik} x_i + a_{jk} x_j + a_{kk} x_k  \nonumber
% \mbox{or } \sum_{i \neq m,k} a_{im} x_i + a_{km} x_m + a_{mm} x_k & & \nonumber
\end{eqnarray}
% where $m = j - N/2$.  This gives rise to 2 sets of equations.
with the restriction $j \in \{ 1,..., N/2 \}$, and $k \in \{ 1,..., N \}$.

The constraints obtained are same as before, except that index ranges are different:
\begin{eqnarray}
a_{ij} &=& a_{ik} \quad \quad \forall \;  j, k, (i \neq j, k) \nonumber \\
a_{kj} &=& a_{jk} \quad \quad \forall \;  j, k \nonumber \\
a_{jj} &=& a_{kk} \quad \quad \forall \;  j, k \nonumber
%\hline \nonumber\\
%a_{ij} &=& a_{ik} \quad \quad \forall \;  j > N/2, k \le N/2, (i \neq j, k) \nonumber \\
%a_{kj} &=& a_{jk} \quad \quad \forall \;  j > N/2, k \le N/2 \nonumber \\
%a_{jj} &=& a_{kk} \quad \quad \forall \;  j > N/2, k \le N/2 \nonumber\\
%\hline \nonumber\\
%a_{ij} &=& a_{ik} \quad \quad \forall \;  j \le N/2, k > N/2, (i \neq j, k) \nonumber \\
%a_{kj} &=& a_{jk} \quad \quad \forall \;  j \le N/2, k > N/2 \nonumber \\
%a_{jj} &=& a_{kk} \quad \quad \forall \;  j \le N/2, k > N/2 \nonumber\\
%\hline \nonumber\\
%a_{ij} &=& a_{ik} \quad \quad \forall \;  j > N/2, k > N/2, (i \neq j, k) \nonumber \\
%a_{kj} &=& a_{jk} \quad \quad \forall \;  j > N/2, k > N/2 \nonumber \\
%a_{jj} &=& a_{kk} \quad \quad \forall \;  j > N/2, k > N/2
\end{eqnarray}

These constraints give rise to a matrix of this form (for the $6 \times 3$ case, numbers represent different colors):
\begin{equation}
\begin{tabular}{c c c c c c c}
5 & 1 & 1 & 2 & 3 & 4 & \\
1 & 5 & 1 & 2 & 3 & 4 & \\
1 & 1 & 5 & 2 & 3 & 4 & .
\end{tabular} 
\end{equation}This pattern is obtained from my Python code.

\subsection{Quadratic case}

\end{document}