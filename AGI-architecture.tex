\documentclass[15pt]{beamer}

\ifdefined\chinchin
\usepackage[CJKspace]{xeCJK}
\setCJKmainfont[BoldFont=SimHei,ItalicFont=AR PL KaitiM GB]{SimSun}
\newcommand{\cc}[2]{#1}
\else
\newcommand{\cc}[2]{#2}
\fi

%\usepackage{newtxtext,newtxmath}	% use Times Roman font
%\usefonttheme{serif}
\usefonttheme{professionalfonts}
%\setbeamertemplate{theorems}[numbered]
\setbeamertemplate{caption}{\insertcaption} 	% no `Figure' prefix before caption

\mode<presentation> {

%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line
\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\setbeamertemplate{headline}{}
\setbeamersize{text margin left=1mm,text margin right=1mm} 
\settowidth{\leftmargini}{\usebeamertemplate{itemize item}}
\addtolength{\leftmargini}{\labelsep}

\usepackage[backend=biber,bibstyle=authoryear,citestyle=../authoryearbrack]{biblatex}
\bibliography{../AGI-book}
\renewcommand*{\bibfont}{\footnotesize}

\usepackage{graphicx} % Allows including images
\usepackage{verbatim} % comments
% \usepackage{tikz-cd}  % commutative diagrams
% \newcommand{\tikzmark}[1]{\tikz[overlay,remember picture] \node (#1) {};}
% \usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
% \usepackage{amssymb}  % \leftrightharpoons
\usepackage{wasysym} % frownie face
\usepackage{newtxtext,newtxmath}	% Times New Roman font

\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\vect}[1]{\boldsymbol{#1}}
\newcommand*\sigmoid{\vcenter{\hbox{\includegraphics{sigmoid.png}}}}
\newcommand*\confoundFace{$\vcenter{\hbox{\includegraphics[scale=0.2]{../confounded-face.jpg}}}$}
\renewcommand{\smiley}{$\vcenter{\hbox{\includegraphics[scale=0.05]{../smiling-face.png}}}$}

\makeatletter
\renewcommand{\boxed}[1]{\fbox{\m@th$\displaystyle\scalebox{0.9}{#1}$} \,}
\makeatother

\newif\ifframeinlbf
\frameinlbftrue
\makeatletter
\newcommand\listofframes{\@starttoc{lbf}}
\makeatother

\addtobeamertemplate{frametitle}{}{%
	\ifframeinlbf
	\addcontentsline{lbf}{section}{\protect\makebox[2em][l]{%
			\protect\usebeamercolor[fg]{structure}\insertframenumber\hfill}%
		\insertframetitle\par}%
	\else\fi
}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[On AGI architecture]{\cc{\Huge《论 AGI 的架构》\\{\footnotesize \today 中期报告}}
	{On AGI architecture \\{\footnotesize \today \ mid-term report}}}

\author{\cc{YKY 甄景贤}{YKY}} % Your name
\institute[] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
Independent researcher, Hong Kong \\ % Your institution for the title page
\medskip
\textit{generic.intelligence@gmail.com} % Your email address
}
\date{} % Date, can be changed to a custom date

\begin{document}

\frameinlbffalse
\frame{\titlepage}

\begin{frame}
\frametitle{Table of contents}
\listofframes
\vspace*{0.5cm}
\cc{
Hello 各位朋友 \smiley

近来有些进展，但只能算是「中段结果」，和大家分享一下。 \\
也希望能找到合作者。
}{
Hello friends \smiley

I have made some intermediate progress recently, which I share below, \\
and also hope to find collaborators.
}
\end{frame}

%---------------- this is for when you're using \part's ----------------------------------
%\begin{frame}
%\frametitle{Summary}
%
%{\usebeamerfont*{frametitle} Part I %\usebeamercolor[fg]{frametitle}
% ~ ~ ~ Deep reinforcement learning}
%%\tableofcontents[part=1]
%
%\vspace{1.5cm}
%{\usebeamerfont*{frametitle} Part II %\usebeamercolor[fg]{frametitle}
% ~ ~ ~ Logical structure}
%%\tableofcontents[part=2]
%\end{frame}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

%------------------------------------------------

%\part{title}

%\section[Section]{}
%\frame{\sectionpage}
\frameinlbftrue
\begin{frame}
\frametitle{\cc{最简单的 AGI 架构}{The simplest AGI architecture}}
\begin{itemize}
	\item 最简单的 AGI 架构是这样的：（它包含一个 recurrent \textbf{回路}）
		\begin{equation}
		\vcenter{\hbox{\includegraphics[scale=0.5]{minimal-architecture.png}}}
		\end{equation}
	\item 它在 \textbf{强化学习} 的框架下，根据 Bellman 最优化条件，将 奖励 最大化
	\item Transition function $F$ 可以用一个 神经网络 实现
	\item 根据我先前解释过的 no free lunch 理论，这个架构的问题是缺乏 inductive bias，学习太慢
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{No free lunch (NFL) 的迷思}
\begin{itemize}
	\item 根据 no free lunch 哲学，没有所谓「好」与「坏」的归纳偏好
	\item 只要能加速学习的，但又不完全 切掉 AGI，都是好 bias
		\begin{equation}
		\vcenter{\hbox{\includegraphics[scale=0.5]{no-free-lunch.png}}}
		\end{equation}
	\item 例如，可以将 $F$ 的神经网络 变 \textbf{稀疏} (sparse)，但保持 深度 (deep)
	\item 但我之前提议用 \textbf{逻辑结构} 作为 bias，是否\red{多此一举}呢？！ \confoundFace 
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{「双回路」架构}
\begin{itemize}
	\item 假设 working memory 是由分离的 \textbf{命题} (\red{\textbullet}) 构成的，可以提出一个「双回路」的架构： (这意思是，例如回路中载有10个命题，则它运转10次，隐状态即「浓缩」了这10个命题的资讯，然后输出一个新命题)
	\begin{equation}
	\vcenter{\hbox{\includegraphics[scale=0.5]{double-loop-architecture.png}}}
	\label{double-loop-arch-1}
	\end{equation}
	\item 这种架构很可能是人脑的架构，因为比较简单，可以进化出来
	\item 据我所知，BERT 架构含有一个回路／一个隐状态 （BERT 逐个输入句子的单词，然后 隐状态 再将输出的单词 逐个吐出来）
	\item 似乎 将 BERT 变成「双回路」，可以得到 AGI： （但我不熟悉 BERT）
	\begin{equation}
		\boxed{\text{单词／概念}} \stackrel{\text{loop 1}}{\longrightarrow} \boxed{\text{句子／命题}} \stackrel{\text{loop 2}}{\longrightarrow} \boxed{\text{mental state}}
	\end{equation}
\end{itemize}
\end{frame}

\begin{frame}[plain]
% \frametitle{「双回路」架构}
\begin{itemize}
	\item 图 (\ref{double-loop-arch-1}) 不够严谨，详细画出来是这样的：
	\begin{equation}
		\label{double-loop-arch}
		\vcenter{\hbox{\includegraphics[scale=0.5]{double-loop-architecture-2.png}}}
	\end{equation}
	\item 相比之下，如果用了 symmetric NN 则架构更简单：
	\begin{equation}
		\label{symNN-arch}
		\vcenter{\hbox{\includegraphics[scale=0.5]{symNN-architecture.png}}}
	\end{equation}
	\item 问题是 (\ref{double-loop-arch}) 和 (\ref{symNN-arch}) 哪个的 学习速度 更快？  但不易判断 \confoundFace
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{强化学习 与 量子力学 之间的联系}
\begin{itemize}
	\item 强化学习 的最优化条件是 \textbf{Bellman} 方程：
		\begin{equation}
			\boxed{\mbox{Bellman}} \quad S_t(x) = \max_u \{ L(x,u) + \gamma S_{t+1}(x) \}
		\end{equation}
	\item 而 Bellman 方程 的 微分形式，是经典分析力学中的 \textbf{Hamilton-Jacobi} 方程 （这点在 1970s 已经为 Kalman 和 Pontryagin 等人认识），现代叫这方程为 Hamilton-Jacobi-Bellman (HJB) 方程：
		\begin{equation}
			\boxed{\mbox{Hamilton-Jacobi}} \quad \frac{\partial S(x, t)}{\partial t} = -H
		\end{equation}
	\item 其中 Lagrangian $L$ 和 Hamiltonian $H$ 之间有关系：
	\begin{equation}
		L = \text{K.E.} - \text{P.E.} \quad , \quad H = \text{K.E.} + \text{P.E.}
	\end{equation}
		$\text{K.E.}$ = kenetic energy, $\text{P.E.}$ = potential energy.
	\item 至此，我们将一条 \textbf{离散}方程 变为 连续函数的\textbf{微分}方程，但\red{没有得益}
\end{itemize}
\end{frame}

\begin{frame}[plain]
\begin{itemize}
	\item 我最近独立发现了从经典力学的 Hamilton-Jacobi 方程 过渡到 Schr\"{o}dinger 方程的 exact 形式，关键是透过 $\Psi = e^{-i \hbar S}$ 此一代入：
		\begin{equation}
		\boxed{\mbox{Hamilton-Jacobi}} \quad \frac{\partial S}{\partial t} = - H \quad
		\Rightarrow
		\quad i \hbar \frac{\partial \Psi}{\partial t} = H \Psi \quad \boxed{\mbox{Schr\"{o}dinger}}
		\end{equation} 
	\item 一直以来，量子力学的教科书 认为这种 量子化 (quantization) 过程 只能够是近似性的。  后有朋友告诉我 \parencite{Field2010} 已导出了这结果。
	\item 从 AI 的角度来看，这结果表示： \red{强化学习 可以 转化为 在 Hilbert 空间中求解 Schr\"{o}dinger 方程！}
	\item 而，Schrodinger 方程可以透过 \textbf{虚数时间} (imaginary time) 转化为 热力学的 \textbf{扩散} (diffusion) 方程
		\begin{equation}
			\boxed{\mbox{wave eqn.}} \quad \frac{\partial \Psi}{\partial t} + i \Delta \Psi = 0
			\quad \leftrightsquigarrow \quad
			\frac{\partial u}{\partial t} + \Delta u = 0 \quad \boxed{\mbox{heat eqn.}}
		\end{equation}
	\item 但应用到 AI 上需要 \textbf{离散化}，特别是利用 discrete Laplacian $\Delta$ 或 discrete Schr\"{o}dinger operators 作用在 \red{graph} 上（状态空间是 graph）
	\item 暂未知这方向有没有好处 \confoundFace
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Topos 理论}
Topos 是指一个能够在里面「\red{做逻辑}」的范畴，它起源於 Lawvere 于 1950s 将 \textbf{集合论} 表述成 \textbf{范畴论} 的尝试。 \\
在一个 topos 范畴内的物体 (objects) 可以进行三种运算：
\begin{itemize}
	\item Cartesian product $A \times B$（对应命题逻辑的 $A \wedge B$）
	\item exponentiation $A \rightarrow B = B^A$ （对应命题逻辑的 $A \Rightarrow B$）
	\item subobject classifier $A \hookrightarrow B$ （表示 \textbf{子集} $A \subseteq B$ 的概念）
\end{itemize}
Topos 理论的重要性在於： 它概括了哪些数学结构有进行 \textbf{逻辑} 的能力，例如一些 relation graphs，algebras 等。 \\
在我的理论里，神经网络 $F$ 负责 $U \stackrel{F}{\rightarrow} V$ 即 exponentiation $V^U$ 这部分，而 $U, V$ 是向量空间。 这至少要求我们将 $A \times B$ 的结构 embed 到向量空间中。 由於 $A \times B = B \times A$ 是\textbf{可交换}的，这促使我看了一下 Abel 群的理论。
\end{frame}

\begin{frame}
\frametitle{交换不变性 (permutation invariance)}
\begin{itemize}
	\item 最近有個颇厉害的想法，将 Word2Vec 嵌入到 Poincar\'{e} disc / hyperbolic space \parencite{Nickel2017}
	\item 类似地，能不能将 逻辑物体 的 vectors 嵌入到 hyperbolic space？ 
	\item 自由群 $F_2$ 的 Cayley 图是\textbf{树}，但 \red{交换}自由群的 Cayley 图是\textbf{格状}的： 
		\begin{equation}
		\vcenter{\hbox{\includegraphics[scale=0.3]{Cayley-graph-F2.png}}}
		\quad \quad \quad
		\vcenter{\hbox{\includegraphics[scale=0.3]{Cayley-graph-Z2.png}}}
		\end{equation}
	\item 一般来说，自由群 $F_n$ 的 Cayley 图可以嵌入到（平面的）hyperbolic disc 上，但 $F_n$ 的 Abelianization $F_n^{\text{Ab}} \cong \mathbb{Z}^n = \mathbb{Z} \times ... \mathbb{Z}$ 是一个 \red{$n$-维} 空间的 grid，似乎不可能嵌入到平面上
	\item 就算考虑 表示论 (representation theory)，所有 Abel 群的不可约复表示 都是 1-维的。 $F_n^{\text{Ab}}$ 的表示，恰好是 $n$ 个 1-维 表示的直和。 没卵用！
\end{itemize}
\end{frame}

\begin{frame}[plain]
% \frametitle{交换不变的 神经网络}
\begin{itemize}
	% \item 就算考虑 表示论 (representation theory)，所有 Abel 群的不可约复表示 都是 1-维的。 $F_n^{\text{Ab}}$ 的表示，恰好是 $n$ 个 1-维 表示的直和。 没卵用！
	\item 上页结论是： $\mathbb{Z}^n$ 不可能嵌入到更低维的空间内，除非使用某种 \red{fractal} 方法。  然而，fractals 恰好是 神经网络 这件武器的「射程范围」之外！ 
	\item 换个想法，通过 类似 weights-sharing 的 \textbf{约束}，令 神经网络 变成 permutation invariant (= \red{Symmetric NN})
	\item 这方法 必需设 activation function = polynomial
	\item 缺点是： 约束的数量 随著 层数 增加而 指数式增长，暂时只能做 1-2 层的，每层 = 2次多项式
	\item 优点是： 反正我们希望 神经网络 是 sparse（减少权重空间的自由度），而这个做法同时具有逻辑 bias
	\item 细节我会在另一篇论文讲述
\end{itemize}
\printbibliography
\begin{center}
	多谢收看 \smiley
\end{center}
\end{frame}

\begin{comment}

\begin{frame}
\frametitle{References}
\footnotesize{
\begin{thebibliography}{99} % Beamer does not support BibTeX so references must be inserted manually as below
\bibitem[]{} Bart Jacobs (1999)
\newblock Categorical logic and type theory
% \newblock \emph{North Holland, Studies in logic} v141.

\bibitem[]{} Robert Goldblatt (2006)
\newblock Topoi -- the categorical analysis of logic

\end{thebibliography}
}
\end{frame}

\end{comment}

\end{document} 